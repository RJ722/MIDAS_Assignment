{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8fTYpzdVqDh2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K, regularizers, optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pSz0JZK2qDil"
   },
   "outputs": [],
   "source": [
    "with open(PATH + \"train_image.pkl\", 'rb') as f:\n",
    "    X = np.array(pickle.load(f))\n",
    "    \n",
    "with open(PATH + 'train_label.pkl', 'rb') as f:\n",
    "    Y = np.array(pickle.load(f))\n",
    "\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ENSRzkNyqDi8"
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2He7QZQqDjV"
   },
   "source": [
    "## Data Exploration\n",
    "\n",
    "Now, let's look at what we've got here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "A_82qTmBqDjf",
    "outputId": "2a53aa7b-d12c-436f-adf2-15b0c69f8651",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of training data: \n",
      "(6000, 784)\n",
      "(6000,)\n",
      "Dimensions of validation data: \n",
      "(2000, 784)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of training data: \")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Dimensions of validation data: \")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-2HV8QROqDkE"
   },
   "source": [
    "`784`, interesting - That is a (28, 28) image. Let's look at some of these below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "colab_type": "code",
    "id": "TLT1KBqcqDkP",
    "outputId": "9b30297e-9c7f-4160-9187-04fc3ffe8fbe"
   },
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, 6001, size=(25,))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(x_train[random_index[i]].reshape((28, 28)))\n",
    "    plt.xlabel(y_train[random_index[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hSTWEvFqqDkj"
   },
   "source": [
    "#### Fashion MNIST\n",
    "\n",
    "Ah, the classic Fashion MNIST set. This is gonna be interesting. Let's try some basic machine learning techniques first.\n",
    "\n",
    "Let's first create a helper function so that we can assess the performance of a model easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SEef0wy6qDko"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    y_pred = model.predict(x_val)\n",
    "    print(\"Classifciation Report:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\")\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    print(\"\\nAccuracy of the model on validation set: {}\".format(\n",
    "        model.score(x_val, y_val)))\n",
    "    print(\"Accuracy of the model on Training set: {}\".format(\n",
    "        model.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NLDVw1_xqDk6"
   },
   "source": [
    "#### Let's try SVM first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "vEdiYL07qDk7",
    "outputId": "ee55cab4-17e4-4382-ce87-fd382914d67c"
   },
   "outputs": [],
   "source": [
    "SVC = svm.SVC(gamma='scale').fit(x_train, y_train)\n",
    "evaluate_model(SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xrPx8yq7qDlM"
   },
   "source": [
    "83% accuracy on first go. We're upto a great start. Let's try some other things now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "tGXbhm1rqDlT",
    "outputId": "2503aba3-4fcb-4dd3-aed8-2bc86734e660"
   },
   "outputs": [],
   "source": [
    "dtree_model = DecisionTreeClassifier(max_depth = 17).fit(x_train, y_train)\n",
    "evaluate_model(dtree_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vv4R2ZNbqze0"
   },
   "source": [
    "This shows clear signs of overfitting. Let's try a different `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "YFSMxtubqDlt",
    "outputId": "02947be9-6cfa-4671-9e86-8d068f8a47b2"
   },
   "outputs": [],
   "source": [
    "dtree_model = DecisionTreeClassifier(max_depth=25).fit(x_train, y_train)\n",
    "evaluate_model(dtree_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "hO-IpibxqDmE",
    "outputId": "76f12830-3c9b-4035-974a-f8d45b190109"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(x_train, y_train)\n",
    "evaluate_model(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "colab_type": "code",
    "id": "Nkz1gv_-qDmV",
    "outputId": "1c2268b7-700e-4742-b34a-bbd83fc5ed27"
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(min_samples_leaf=20).fit(x_train, y_train)\n",
    "evaluate_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "colab_type": "code",
    "id": "zNNS5j62qDms",
    "outputId": "3af3f4fa-e469-426a-daf0-a5f9d0834b83"
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(min_samples_leaf=10).fit(x_train, y_train)\n",
    "evaluate_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "colab_type": "code",
    "id": "_AFNbfZPqDnG",
    "outputId": "df745392-d95d-4547-d2bc-6435233bb9ff"
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(min_samples_leaf=5).fit(x_train, y_train)\n",
    "evaluate_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "colab_type": "code",
    "id": "jdRgica2qDng",
    "outputId": "bbcd98f2-fcee-4b18-8be8-e11650f0c4dd"
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(min_samples_leaf=4).fit(x_train, y_train)\n",
    "evaluate_model(rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zuIatK4bqDoA"
   },
   "source": [
    "Hmm, SVM seems to be the winner here. Let's try a grid search for parameters in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "NMTLP7zIqDoD",
    "outputId": "cf79295c-f60b-43bb-bca2-7b8afba0dd47"
   },
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC(gamma=\"scale\")\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "08MdtHRMqDoh",
    "outputId": "bd983347-0b8d-40ef-dc59-36c8dd4d3ce6"
   },
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nxclKuk4qDo0",
    "outputId": "41ad50ae-e3b3-438c-f978-0f4ed6b0a767"
   },
   "outputs": [],
   "source": [
    "clf.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "rMfXhPBFqDpQ",
    "outputId": "944b5882-16e2-4257-9b40-8e5d6bdf2eeb"
   },
   "outputs": [],
   "source": [
    "evaluate_model(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTwGK9j3qDpz"
   },
   "source": [
    "Woohoo, `85%` is decent enough accuracy for submission. Our results seem match the [standard benchmark results].\n",
    "\n",
    "[standard benchmark results]: http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PXpm4BmxqDp6"
   },
   "source": [
    "### Let's try a basic Convolutional Neural Network\n",
    "\n",
    "We've already reached a pretty high accuracy bar, but according to [zalando research], many CNN based architectures have had also been pretty successful. Since, I do not have as much data as in the original Fashion MNIST, I should train on a relatively simpler architecture.\n",
    "\n",
    "[zalando research]: [https://github.com/zalandoresearch/fashion-mnist#benchmark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3j_R5EcrqDqB"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 7\n",
    "epochs = 20\n",
    "\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6J_dEIC4qDqT"
   },
   "outputs": [],
   "source": [
    "# Since K.image_data_format == 'channels_last':\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_val = x_val.reshape(x_val.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "colab_type": "code",
    "id": "t1innwI3qDqe",
    "outputId": "bddc7a2f-3fc8-401d-8d9d-5928452e1b32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000,)\n",
      "(2000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1482.,    0.,    0., 1482.,    0., 1545.,    0.,    0.,    0.,\n",
       "        1491.]),\n",
       " array([0. , 0.6, 1.2, 1.8, 2.4, 3. , 3.6, 4.2, 4.8, 5.4, 6. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qfo-r69CqDqt"
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_val = keras.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "YniE8-4YqDq8",
    "outputId": "d19ad5e0-667e-4c63-a77d-c5e2209245bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 7)\n",
      "(2000, 7)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "pLzLsRewqDrO",
    "outputId": "664768db-c037-48a0-fd62-24786f54bbe4"
   },
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "\n",
    "cnn.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "cnn.add(Dropout(0.25))\n",
    "cnn.add(Conv2D(64, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn.add(Dropout(0.25))\n",
    "cnn.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "cnn.add(Dropout(0.4))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "cnn.add(Dropout(0.3))\n",
    "cnn.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 812
    },
    "colab_type": "code",
    "id": "V64kzhQ4qDrb",
    "outputId": "5cf97244-b28a-4973-d2ad-57b8e7abd01b"
   },
   "outputs": [],
   "source": [
    "cnn.fit(x_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=20,\n",
    "        verbose=1,\n",
    "        validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "I3P9NinJqDrv",
    "outputId": "1ab6ecbe-556d-4c82-a02e-40d6017e600f"
   },
   "outputs": [],
   "source": [
    "y_pred = cnn.predict_classes(x_val)\n",
    "y_val_confusion = [np.argmax(encoded_label) for encoded_label in y_val]\n",
    "print(\"Classification Report: \\n\", classification_report(y_val_confusion, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_val_confusion, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BitJxpXOxEXA"
   },
   "source": [
    "### Let's try Data Augmentation\n",
    "\n",
    "We augment additional examples in the `x/y_aug_train` and `x/y_aug_val` by augmenting data present in `x/y_train`. The data from `x/y_val` shall serve as a test data set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jsjKIrKWqDsG"
   },
   "outputs": [],
   "source": [
    "# Defines the options for augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    horizontal_flip=True,\n",
    "    # fill_mode='nearest'\n",
    ")\n",
    "\n",
    "number_of_augmentation = 2\n",
    "\n",
    "def image_augmentation(image):\n",
    "    '''\n",
    "    Generates new images.\n",
    "    '''\n",
    "    images = []\n",
    "    # Take a 28, 28 image and transform into (1, 28, 28, 1)\n",
    "    image = image.reshape(1, img_rows, img_cols, 1)\n",
    "    i = 0\n",
    "    for x_batch in datagen.flow(image, batch_size=1):\n",
    "        images.append(x_batch)\n",
    "        i += 1\n",
    "        if i >= number_of_augmentation:\n",
    "            break\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4zDhwmyLwm6u"
   },
   "outputs": [],
   "source": [
    "def augment_data(x, y):\n",
    "    no_of_training_ex = x.shape[0]\n",
    "    x_aug = []\n",
    "    y_aug = []\n",
    "    for i in range(no_of_training_ex):\n",
    "        image = x[i] # Image is (28, 28)\n",
    "        label = y[i]\n",
    "        aug_images = image_augmentation(image)\n",
    "        for aug_image in aug_images:\n",
    "            x_aug.append(aug_image.reshape((28, 28)))\n",
    "            y_aug.append(label)\n",
    "        # Now, also save the original image\n",
    "        x_aug.append(image)\n",
    "        y_aug.append(label)\n",
    "    x_aug = np.array(x_aug)\n",
    "    y_aug = np.array(y_aug)\n",
    "    return x_aug, y_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 28, 28)\n",
      "(6000,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "pWTfKidWxrpn",
    "outputId": "4c82199d-2566-4422-e79f-53a930f718d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 28, 28)\n",
      "(18000,)\n"
     ]
    }
   ],
   "source": [
    "x_aug_data, y_aug_data = augment_data(x_train, y_train)\n",
    "\n",
    "print(x_aug_data.shape)\n",
    "print(y_aug_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_aug_train, x_aug_val, y_aug_train, y_aug_val = train_test_split(x_aug_data, y_aug_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "1kaIzKA0x4et",
    "outputId": "20cecd8f-0bbf-4d38-8679-4fef39c4bca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13500, 28, 28, 1)\n",
      "(13500,)\n",
      "(4500, 28, 28, 1)\n",
      "(4500,)\n"
     ]
    }
   ],
   "source": [
    "x_aug_train = x_aug_train.reshape(x_aug_train.shape[0], 28, 28 , 1).astype('float32')\n",
    "x_aug_val = x_aug_val.reshape(x_aug_val.shape[0], 28, 28 , 1).astype('float32')\n",
    "\n",
    "# y_aug_train = keras.utils.to_categorical(y_aug_train)\n",
    "# y_aug_val = keras.utils.to_categorical(y_aug_val)\n",
    "\n",
    "print(x_aug_train.shape)\n",
    "print(y_aug_train.shape)\n",
    "print(x_aug_val.shape)\n",
    "print(y_aug_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "h92hTCysyU4K",
    "outputId": "0c383ff4-8123-4776-d516-2741d9537d8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's visualise our transforms\n",
    "\n",
    "i = 3455\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "ax1.imshow(x_train[i].reshape(28, 28))\n",
    "ax2.imshow(x_aug_data[3*(i-1) + 3].reshape(28, 28))\n",
    "ax3.imshow(x_aug_data[3*(i-1) + 4].reshape(28, 28))\n",
    "ax4.imshow(x_aug_data[3*(i-1) + 5].reshape(28, 28))\n",
    "\n",
    "print(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ot0oBQMyk_f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "cnn_2 = Sequential()\n",
    "\n",
    "cnn_2.add(InputLayer(input_shape=(img_rows, img_cols, 1)))\n",
    "cnn_2.add(BatchNormalization())\n",
    "cnn_2.add(Conv2D(64, (4, 4), padding='same', activation='relu'))\n",
    "cnn_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_2.add(Dropout(0.1))\n",
    "cnn_2.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "cnn_2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_2.add(Dropout(0.3))\n",
    "cnn_2.add(Flatten())\n",
    "cnn_2.add(Dense(256, activation='relu'))\n",
    "cnn_2.add(Dropout(0.5))\n",
    "cnn_2.add(Dense(64, activation='relu'))\n",
    "cnn_2.add(BatchNormalization())\n",
    "\n",
    "cnn_2.add(Dense(7, activation='softmax'))\n",
    "\n",
    "cnn_2.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizers.Adam(),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aug_train = keras.utils.to_categorical(y_aug_train)\n",
    "y_aug_val = keras.utils.to_categorical(y_aug_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "prFA22qty-WP",
    "outputId": "e8ab1a11-ee5a-45a7-b3b6-f564d5e7a7cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 13500 samples, validate on 4500 samples\n",
      "Epoch 1/40\n",
      "13500/13500 [==============================] - 3s 201us/step - loss: 0.9812 - acc: 0.6537 - val_loss: 0.6350 - val_acc: 0.7807\n",
      "Epoch 2/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.5691 - acc: 0.7859 - val_loss: 0.4322 - val_acc: 0.8320\n",
      "Epoch 3/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.4845 - acc: 0.8121 - val_loss: 0.4014 - val_acc: 0.8411\n",
      "Epoch 4/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.4354 - acc: 0.8296 - val_loss: 0.3617 - val_acc: 0.8569\n",
      "Epoch 5/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.4131 - acc: 0.8372 - val_loss: 0.3525 - val_acc: 0.8620\n",
      "Epoch 6/40\n",
      "13500/13500 [==============================] - 1s 70us/step - loss: 0.3772 - acc: 0.8477 - val_loss: 0.3568 - val_acc: 0.8531\n",
      "Epoch 7/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.3569 - acc: 0.8564 - val_loss: 0.3207 - val_acc: 0.8678\n",
      "Epoch 8/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.3422 - acc: 0.8606 - val_loss: 0.3233 - val_acc: 0.8704\n",
      "Epoch 9/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.3294 - acc: 0.8665 - val_loss: 0.2856 - val_acc: 0.8902\n",
      "Epoch 10/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.3093 - acc: 0.8747 - val_loss: 0.2775 - val_acc: 0.8953\n",
      "Epoch 11/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.2940 - acc: 0.8813 - val_loss: 0.2593 - val_acc: 0.8960\n",
      "Epoch 12/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.2850 - acc: 0.8858 - val_loss: 0.2782 - val_acc: 0.8902\n",
      "Epoch 13/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.2652 - acc: 0.8949 - val_loss: 0.2605 - val_acc: 0.8976\n",
      "Epoch 14/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.2575 - acc: 0.9013 - val_loss: 0.2512 - val_acc: 0.9060\n",
      "Epoch 15/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.2486 - acc: 0.9037 - val_loss: 0.2360 - val_acc: 0.9080\n",
      "Epoch 16/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.2268 - acc: 0.9100 - val_loss: 0.2344 - val_acc: 0.9160\n",
      "Epoch 17/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.2305 - acc: 0.9113 - val_loss: 0.2487 - val_acc: 0.9038\n",
      "Epoch 18/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.2174 - acc: 0.9153 - val_loss: 0.2166 - val_acc: 0.9213\n",
      "Epoch 19/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.2059 - acc: 0.9183 - val_loss: 0.2334 - val_acc: 0.9120\n",
      "Epoch 20/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.1930 - acc: 0.9229 - val_loss: 0.2191 - val_acc: 0.9187\n",
      "Epoch 21/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.1915 - acc: 0.9266 - val_loss: 0.2257 - val_acc: 0.9107\n",
      "Epoch 22/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.1837 - acc: 0.9271 - val_loss: 0.2016 - val_acc: 0.9260\n",
      "Epoch 23/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.1626 - acc: 0.9355 - val_loss: 0.2199 - val_acc: 0.9184\n",
      "Epoch 24/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.1648 - acc: 0.9348 - val_loss: 0.2008 - val_acc: 0.9247\n",
      "Epoch 25/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.1625 - acc: 0.9373 - val_loss: 0.2009 - val_acc: 0.9276\n",
      "Epoch 26/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.1598 - acc: 0.9373 - val_loss: 0.2113 - val_acc: 0.9231\n",
      "Epoch 27/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.1506 - acc: 0.9409 - val_loss: 0.1955 - val_acc: 0.9298\n",
      "Epoch 28/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.1548 - acc: 0.9407 - val_loss: 0.1964 - val_acc: 0.9271\n",
      "Epoch 29/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.1342 - acc: 0.9482 - val_loss: 0.1900 - val_acc: 0.9340\n",
      "Epoch 30/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.1388 - acc: 0.9469 - val_loss: 0.1854 - val_acc: 0.9347\n",
      "Epoch 31/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.1384 - acc: 0.9494 - val_loss: 0.2048 - val_acc: 0.9251\n",
      "Epoch 32/40\n",
      "13500/13500 [==============================] - 1s 69us/step - loss: 0.1308 - acc: 0.9487 - val_loss: 0.1836 - val_acc: 0.9347\n",
      "Epoch 33/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.1198 - acc: 0.9554 - val_loss: 0.2004 - val_acc: 0.9329\n",
      "Epoch 34/40\n",
      "13500/13500 [==============================] - 1s 69us/step - loss: 0.1219 - acc: 0.9541 - val_loss: 0.1905 - val_acc: 0.9387\n",
      "Epoch 35/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.1168 - acc: 0.9569 - val_loss: 0.2086 - val_acc: 0.9287\n",
      "Epoch 36/40\n",
      "13500/13500 [==============================] - 1s 67us/step - loss: 0.1230 - acc: 0.9538 - val_loss: 0.1940 - val_acc: 0.9378\n",
      "Epoch 37/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.1097 - acc: 0.9585 - val_loss: 0.1921 - val_acc: 0.9324\n",
      "Epoch 38/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.1094 - acc: 0.9568 - val_loss: 0.1976 - val_acc: 0.9322\n",
      "Epoch 39/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.1082 - acc: 0.9596 - val_loss: 0.1859 - val_acc: 0.9373\n",
      "Epoch 40/40\n",
      "13500/13500 [==============================] - 1s 68us/step - loss: 0.1125 - acc: 0.9553 - val_loss: 0.1865 - val_acc: 0.9376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f691b1c67f0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_2.fit(x_aug_train, y_aug_train, batch_size=batch_size, epochs=40, verbose=1, validation_data=(x_aug_val, y_aug_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUcmZS4Tz8Ag"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set (augmented):  0.9375555555025736\n"
     ]
    }
   ],
   "source": [
    "score = cnn_2.evaluate(x_aug_val, y_aug_val, verbose=0)\n",
    "print(\"Accuracy on the validation set (augmented): \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_val.reshape(x_val.shape[0], 28, 28, 1)\n",
    "y_val = keras.utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set:  0.955\n"
     ]
    }
   ],
   "source": [
    "score = cnn_2.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"Accuracy on the test set: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`95.5%` - We are good to go. \\o/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../input/test-images-midas-assignment/\"\n",
    "\n",
    "with open(PATH + \"test_image.pkl\", 'rb') as f:\n",
    "    x_final = np.array(pickle.load(f))\n",
    "\n",
    "x_final = x_final / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_final = x_final.reshape(x_final.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnn_2.predict_classes(x_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('Rahul_Jha.csv', mode='w') as f:\n",
    "    writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(['image_index', 'class'])\n",
    "\n",
    "    for i in range(len(x_final)):\n",
    "        writer.writerow([i, y_pred[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CV Problem.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
